---
title: "drake"
subtitle: "data frames in R for Make"
author: "William Michael Landau"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
    number_sections: true
vignette: >
  %\VignetteIndexEntry{drake}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, echo = F}
suppressMessages(suppressWarnings(library(drake)))
suppressMessages(suppressWarnings(library(magrittr)))
unlink(".drake", recursive = TRUE)
clean(destroy = TRUE, verbose = FALSE)
unlink(c("Makefile", "report.Rmd", "shell.sh", "STDIN.o*", "Thumbs.db"))
knitr::opts_chunk$set(
  collapse = TRUE,
  error = TRUE,
  warning = TRUE
)
```

![](logo-vignettes.png)

Reproducibility carries the promise that your output matches your input. Your tables, figures, reports, and intermediate objects should stay up to date with all the underlying data and code. To ensure internal consistency, `drake` detects and refreshes the outdated components of your project. The same solution unlocks powerful high-performance computing functionality.

# Reproducibility with `drake`

Outline your project as a data frame of targets.

```{r myplandrakevig}
load_basic_example(verbose = FALSE)
my_plan
```

Wildcard templating generates these data frames at scale.

```{r plan_drakegeneration}
library(magrittr)
dataset_plan <- plan_drake(
  small = simulate(5),
  large = simulate(50)
)
dataset_plan

analysis_methods <- plan_drake(
  regression = regNUMBER(dataset__) # nolint
) %>%
  evaluate_plan(wildcard = "NUMBER", values = 1:2)
analysis_methods

analysis_plan <- plan_analyses(
  plan = analysis_methods,
  datasets = dataset_plan
)
analysis_plan

whole_plan <- rbind(dataset_plan, analysis_plan)
whole_plan
```

Using static code analysis, `drake` detects the dependencies of all your targets. The result is an interactive network diagram.

```{r drakevisgraph, eval = FALSE}
vis_drake_graph(my_plan)
```

<iframe
src = "https://cdn.rawgit.com/wlandau-lilly/drake/bd8a086f/images/outdated.html"
width = "100%" height = "600px" allowtransparency="true"
style="border: none; box-shadow: none">
</iframe>

At this point, all your targets are out of date because the project is new.

```{r outdateddrake}
config <- drake_config(my_plan, verbose = FALSE) # Master configuration list
outdated(config)
```

The `make()` function traverses the network and builds the targets that require updates.

```{r firstmakedrake}
make(my_plan)
```

The project is now up to date, so the next `make()` does nothing.

```{r makeuptodatedrake}
make(my_plan)
```

But a nontrivial change in `reg2()` triggers updates to all the affected downstream targets.

```{r reg2makedrake}
reg2 <- function(d){
  d$x3 <- d$x ^ 3
  lm(y ~ x3, data = d)
}

make(my_plan)
```

# High-performance computing

Local parallel processing is easy..

```{r jobsdrake, eval = FALSE}
make(my_plan, jobs = 2)
```

Choose from the available parallel backends.

```{r parallelchoices}
parallelism_choices()
```

```{r makeparLapply, eval = FALSE}
make(my_plan, parallelism = "parLapply", jobs = 4)
```

`Drake` integrates with [future](https://github.com/HenrikBengtsson/future) and [future.batchtools](https://github.com/HenrikBengtsson/future.batchtools) to unlock a multitude of local and distributed computing options. Deployment to a [SLURM](https://slurm.schedmd.com) cluster, for example, is straightforward.

```{r exampleconfiguredrake, eval = FALSE}
library(future.batchtools)
drake_batchtools_tmpl_file("slurm")
future::plan(
  batchtools_slurm(
    template = "batchtools.slurm.tmpl",
    workers = 8
  )
)
make(my_plan, parallelism = "future", jobs = 4)
```

`Drake` even helps you scale the parallel processing.

```{r maxusefuljobs}
# Everything is already up to date.
config <- drake_config(my_plan, verbose = FALSE)
max_useful_jobs(config)

# Change a dependency.
reg2 <- function(d){
  d$x4 <- d$x ^ 4
  lm(y ~ x4, data = d)
}

# The targets that depend on reg2() are now outdated.
max_useful_jobs(config)
```

To make its recommendation, `max_useful_jobs()`, relies on `drake`'s approach to [implicit parallelism](https://www.computerhope.com/jargon/i/implicit-parallelism.htm).

```{r reg2graphdrake, eval = FALSE}
vis_drake_graph(config)
```

<iframe
src = "https://cdn.rawgit.com/wlandau-lilly/drake/bd8a086f/images/reg2.html"
width = "100%" height = "600px" allowtransparency="true"
style="border: none; box-shadow: none">
</iframe>

Within each column above, the nodes are conditionally independent given their dependencies. Each `make()` walks through the columns from left to right and applies parallel processing within each column. If any nodes are already up to date, `drake` looks downstream to maximize the number of outdated targets in a parallelizable stage. To show the parallelizable stages of the next `make()` programmatically, use the `parallel_stages()` function.

# Acknowledgements and related work

The original idea of a time-saving reproducible build system extends back at least as far as [GNU Make](http://kbroman.org/minimal_make/), which still aids the work of [data scientists](http://blog.kaggle.com/2012/10/15/make-for-data-scientists/) as well as the original user base of complied language programmers. In fact, the name "drake" stands for "Data Frames in R for Make".

Today, there is a [whole ecosystem of pipeline toolkits](https://github.com/pditommaso/awesome-pipeline), mostly written in Python. Of all the toolkits in the list, [Rich FitzJohn](http://richfitz.github.io/)'s [remake package](https://github.com/richfitz/remake) is by far the most important for `drake`. `Drake` stands squarely on the shoulders of [remake](https://github.com/richfitz/remake), borrowing the fundamental concepts and extending them in a fresh implementation with a convenient interface and high-performance computing.

Many thanks to the following people for contributing amazing ideas and code patches early in the development of `drake` and its predecessors [parallelRemake](https://github.com/wlandau/parallelRemake) and [remakeGenerator](https://github.com/wlandau/remakeGenerator).

- [Alex Axthelm](https://github.com/AlexAxthelm)
- [Chan-Yub Park](https://github.com/mrchypark)
- [Daniel Falster](https://github.com/dfalster)
- [Eric Nantz](https://github.com/enantz-lilly)
- [Henrik Bengtsson](https://github.com/HenrikBengtsson)
- [Jarad Niemi](http://www.jarad.me/)
- [Jasper Clarkberg](https://github.com/dapperjapper)
- [Kendon Bell](https://github.com/kendonB)
- [Kirill M&uuml;ller](https://github.com/krlmlr)

Special thanks to [Jarad Niemi](http://www.jarad.me/), my advisor from [graduate school](http://stat.iastate.edu/), for first introducing me to the idea of [Makefiles](https://www.gnu.org/software/make/) for research. It took several months to convince me, and I am glad he succeeded.
/github.com/pditommaso/awesome-pipeline), but few are R-focused.

```{r rmfiles_main, echo = FALSE}
clean(destroy = TRUE, verbose = FALSE)
unlink(c("Makefile", "report.Rmd", "shell.sh", "STDIN.o*", "Thumbs.db"))
```
